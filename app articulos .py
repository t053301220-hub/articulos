import streamlit as st
import requests
import pandas as pd
import plotly.express as px
from supabase import create_client, Client
import datetime
import json
from io import BytesIO
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.pagesizes import letter
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet

# =============================
# CONFIGURACI√ìN BASE
# =============================
st.set_page_config(page_title="Asistente de B√∫squeda Cient√≠fica", layout="wide")
st.title("üî¨ Asistente de B√∫squeda Cient√≠fica")

# Conexi√≥n a Supabase
url = st.secrets["https://ypdtrkvebwjiqlmryaoc.supabase.co"]
key = st.secrets["eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InlwZHRya3ZlYndqaXFsbXJ5YW9jIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjEyNTIzNjEsImV4cCI6MjA3NjgyODM2MX0.cWzJQ59oY8xgZvBJ0I7a1a4XWXkRfeIdHbC3PSzVG4w"]
supabase: Client = create_client(url, key)

# URL del Webhook de n8n
WEBHOOK_URL = "https://eriks20252.app.n8n.cloud/webhook/busqueda-cientifica"

# =============================
# FUNCIONES AUXILIARES
# =============================

def generar_pdf(df, tema, resumen_estadistico):
    """Genera un PDF con los art√≠culos y resumen estad√≠stico."""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    styles = getSampleStyleSheet()
    content = []

    content.append(Paragraph(f"Asistente de B√∫squeda Cient√≠fica", styles["Title"]))
    content.append(Paragraph(f"Tema: <b>{tema}</b>", styles["Heading2"]))
    content.append(Spacer(1, 10))

    # Resumen estad√≠stico
    content.append(Paragraph("üìä Resumen estad√≠stico:", styles["Heading3"]))
    for k, v in resumen_estadistico.items():
        content.append(Paragraph(f"{k}: {v}", styles["Normal"]))
    content.append(Spacer(1, 10))

    # Tabla de art√≠culos
    content.append(Paragraph("üìö Art√≠culos encontrados:", styles["Heading3"]))
    data = [["T√≠tulo", "Autores", "A√±o", "Fuente"]]
    for _, r in df.iterrows():
        data.append([r["titulo"], r["autores"], str(r["a√±o"]), r["fuente"]])
    table = Table(data, colWidths=[200, 150, 50, 80])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),
        ('GRID', (0,0), (-1,-1), 0.5, colors.grey)
    ]))
    content.append(table)
    doc.build(content)
    buffer.seek(0)
    return buffer

def mostrar_estadistica(df):
    """Genera estad√≠sticas descriptivas visuales dentro de Streamlit."""
    st.subheader("üìä Estad√≠stica descriptiva")

    c1, c2, c3 = st.columns(3)
    c1.metric("Total art√≠culos", len(df))
    c2.metric("Fuentes √∫nicas", df["fuente"].nunique())
    c3.metric("A√±os distintos", df["a√±o"].nunique())

    df["a√±o"] = pd.to_numeric(df["a√±o"], errors="coerce")

    # Distribuci√≥n por a√±o
    st.markdown("#### Distribuci√≥n de publicaciones por a√±o")
    fig_year = px.histogram(df, x="a√±o", nbins=15, title="Publicaciones por a√±o", color_discrete_sequence=["#636EFA"])
    st.plotly_chart(fig_year, use_container_width=True)

    # A√±o m√°s frecuente
    if df["a√±o"].notna().any():
        a√±o_mas_publicado = int(df["a√±o"].mode().iloc[0])
        total_a√±o = (df["a√±o"] == a√±o_mas_publicado).sum()
        st.info(f"üìÜ A√±o con m√°s publicaciones: {a√±o_mas_publicado} ({total_a√±o} art√≠culos)")

    # Palabras clave m√°s comunes
    if "palabras_clave" in df.columns:
        keywords = []
        for kw in df["palabras_clave"].dropna():
            keywords.extend([k.strip() for k in kw.split(",") if k.strip()])
        if keywords:
            kw_df = pd.DataFrame({"Palabra clave": keywords})
            top_kw = kw_df["Palabra clave"].value_counts().head(10)
            st.markdown("#### Palabras clave m√°s frecuentes")
            fig_kw = px.bar(
                x=top_kw.index, y=top_kw.values,
                title="Palabras clave m√°s frecuentes",
                color_discrete_sequence=["#EF553B"]
            )
            st.plotly_chart(fig_kw, use_container_width=True)

# =============================
# INTERFAZ PRINCIPAL
# =============================

tabs = st.tabs(["üîç B√∫squeda", "üìú Historial"])

# ---------- TAB 1: B√∫squeda ----------
with tabs[0]:
    with st.form("form_busqueda"):
        tema = st.text_input("üìö Tema de investigaci√≥n", "")
        c1, c2 = st.columns(2)
        with c1:
            fecha_inicio = st.date_input("üìÖ Fecha inicio", datetime.date(2020,1,1))
        with c2:
            fecha_fin = st.date_input("üìÖ Fecha fin", datetime.date.today())
        idioma = st.selectbox("üåê Idioma", ["en,es", "en", "es"])
        buscar = st.form_submit_button("üîç Buscar art√≠culos")

    if buscar and tema:
        with st.spinner("Buscando art√≠culos..."):
            try:
                payload = {
                    "tema": tema,
                    "fechaInicio": str(fecha_inicio),
                    "fechaFin": str(fecha_fin),
                    "idioma": idioma
                }
                res = requests.post(WEBHOOK_URL, json=payload)
                res.raise_for_status()
                data = res.json()

                articles = [a.get("json", a) for a in data] if isinstance(data, list) else []
                if not articles:
                    st.warning("‚ö†Ô∏è No se encontraron art√≠culos para ese tema.")
                else:
                    df = pd.DataFrame(articles)
                    st.success(f"‚úÖ {len(df)} art√≠culos encontrados para '{tema}'")

                    # Guardar b√∫squeda en Supabase
                    supabase.table("search_logs").insert({
                        "search_term": tema,
                        "fecha_inicio": str(fecha_inicio),
                        "fecha_fin": str(fecha_fin),
                        "idioma": idioma,
                        "results_count": len(df),
                        "results_data": json.dumps(articles)
                    }).execute()

                    st.markdown("### üìÑ Resultados encontrados")
                    for _, r in df.iterrows():
                        with st.expander(f"üìë {r['titulo']} ({r['a√±o']})"):
                            st.markdown(f"**Autores:** {r['autores']}")
                            st.markdown(f"**Fuente:** {r['fuente']}")
                            st.markdown(f"**Resumen:** {r['resumen'][:500]}...")
                            if r.get("url"):
                                st.markdown(f"[üîó Ver art√≠culo completo]({r['url']})", unsafe_allow_html=True)

                    mostrar_estadistica(df)

                    resumen = {
                        "Art√≠culos encontrados": len(df),
                        "Fuentes √∫nicas": df["fuente"].nunique(),
                        "A√±os distintos": df["a√±o"].nunique()
                    }

                    pdf_buffer = generar_pdf(df, tema, resumen)
                    st.download_button(
                        label="üì• Descargar PDF de resultados",
                        data=pdf_buffer,
                        file_name=f"busqueda_{tema}.pdf",
                        mime="application/pdf"
                    )

            except Exception as e:
                st.error(f"‚ùå Error al realizar la b√∫squeda: {e}")

# ---------- TAB 2: Historial ----------
with tabs[1]:
    st.subheader("üìú Historial de b√∫squedas previas")
    res = supabase.table("search_logs").select("*").order("search_date", desc=True).execute()
    registros = res.data or []

    if not registros:
        st.info("No hay b√∫squedas registradas a√∫n.")
    else:
        df_hist = pd.DataFrame(registros)
        if "search_date" in df_hist.columns:
            df_hist["search_date"] = pd.to_datetime(df_hist["search_date"])

        st.dataframe(df_hist[["search_date", "search_term", "idioma", "results_count"]])

        st.markdown("#### üìà Estad√≠sticas globales")
        fig1 = px.histogram(df_hist, x="search_term", y="results_count", title="Frecuencia de temas buscados", color_discrete_sequence=["#00CC96"])
        st.plotly_chart(fig1, use_container_width=True)

        fig2 = px.pie(df_hist, names="idioma", title="Idiomas utilizados")
        st.plotly_chart(fig2, use_container_width=True)

        # üîé Nuevo: ver detalles de cada b√∫squeda pasada
        st.markdown("### üîé Ver detalles de una b√∫squeda anterior")
        selected_search = st.selectbox("Selecciona una b√∫squeda para ver sus art√≠culos:", df_hist["search_term"].unique())

        if selected_search:
            detalle = df_hist[df_hist["search_term"] == selected_search].iloc[0]
            articles_prev = json.loads(detalle["results_data"])
            df_prev = pd.DataFrame(articles_prev)
            st.success(f"üìö {len(df_prev)} art√≠culos encontrados para '{selected_search}'")

            for _, r in df_prev.iterrows():
                with st.expander(f"üìë {r['titulo']} ({r['a√±o']})"):
                    st.markdown(f"**Autores:** {r['autores']}")
                    st.markdown(f"**Fuente:** {r['fuente']}")
                    st.markdown(f"**Resumen:** {r['resumen'][:500]}...")
                    if r.get("url"):
                        st.markdown(f"[üîó Ver art√≠culo completo]({r['url']})", unsafe_allow_html=True)

            mostrar_estadistica(df_prev)

            resumen_prev = {
                "Art√≠culos encontrados": len(df_prev),
                "Fuentes √∫nicas": df_prev["fuente"].nunique(),
                "A√±os distintos": df_prev["a√±o"].nunique()
            }

            pdf_prev = generar_pdf(df_prev, selected_search, resumen_prev)
            st.download_button(
                label=f"üì• Descargar PDF de '{selected_search}'",
                data=pdf_prev,
                file_name=f"busqueda_{selected_search}.pdf",
                mime="application/pdf"
            )

        # üìò PDF global del historial
        resumen_global = {
            "Total b√∫squedas": len(df_hist),
            "Art√≠culos totales": df_hist["results_count"].sum(),
            "Temas √∫nicos": df_hist["search_term"].nunique()
        }
        pdf_hist = generar_pdf(df_hist.rename(columns={
            "search_term": "titulo",
            "idioma": "fuente",
            "results_count": "a√±o",
            "search_date": "autores"
        }), "Historial global", resumen_global)
        st.download_button("üì• Descargar informe global PDF", pdf_hist, "historial_busquedas.pdf", mime="application/pdf")

